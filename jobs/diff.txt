Only in scaling: checkpoints
Only in scaling: compare_mem.py
Only in scaling/data/ood_images: abs.png
Only in scaling/data: results
diff -bur 15648/datasets.py scaling/datasets.py
--- 15648/datasets.py	2018-11-02 01:46:25.000000001 -0700
+++ scaling/datasets.py	2018-10-30 19:41:39.000000001 -0700
@@ -28,6 +28,7 @@
         data_dir=DATA_DIR,
         source_task="rgb",
         dest_task="normal",
+        debug=False,
         source_transforms=transforms.ToTensor(),
         dest_transforms=transforms.ToTensor(),
     ):
@@ -42,6 +43,7 @@
             self.source_files += sorted(glob.glob(f"{data_dir}/{building}_{source_task}/{source_task}/*.png"))
         # self.source_files = [y for x in self.source_files for y in x]
         print ("Source files len: ", len(self.source_files))
+        self.debug = debug
 
     def __len__(self):
         return len(self.source_files)
@@ -53,17 +55,26 @@
         data_dir, building, task, view = (self.data_dir, result["building"], result["task"], result["view"])
         dest_file = f"{data_dir}/{building}_{self.dest_task}/{self.dest_task}/{view}_domain_{self.dest_task}.png"
 
+        if not os.path.exists(dest_file):
+            time.sleep(0.1)
+            return self.__getitem__(random.randrange(0, len(self.source_files)))
+
         try:
             image = Image.open(source_file)
             image = self.source_transforms(image).float()
 
             task = Image.open(dest_file)
             task = self.dest_transforms(task).float()
-            return image, task
-        except:
-            # print ("Error in file pair: ", source_file, dest_file)
+        except Exception as e:
+            if self.debug: print (e)
             time.sleep(0.1)
             return self.__getitem__(random.randrange(0, len(self.source_files)))
+        return image, task
+        
+        # except:
+        #     # print ("Error in file pair: ", source_file, dest_file)
+        #     time.sleep(0.1)
+        #     return self.__getitem__(random.randrange(0, len(self.source_files)))
 
 
 class ImageDataset(Dataset):
Only in scaling/experiments: benchmark.py
Only in scaling/experiments: cycle_consistency.py
Only in 15648/experiments: __init__.py
Only in 15648/experiments: loss_stats.py
Only in 15648/experiments/__pycache__: __init__.cpython-36.pyc
Only in scaling/experiments/__pycache__: train_mnist.cpython-36.pyc
Only in 15648/experiments/__pycache__: train_normal_curvature.cpython-36.pyc
Only in 15648/experiments/__pycache__: train_perceptual_curvature.cpython-36.pyc
Only in 15648/experiments/__pycache__: train_perceptuals.cpython-36.pyc
Only in scaling/experiments/__pycache__: train_perceptuals.cpython-37.pyc
Only in scaling/experiments: standardization.sh
Only in scaling/experiments: test.py
Only in scaling/experiments: train_augmented.py
Only in scaling/experiments: train_curvature_normals.py
diff -bur 15648/experiments/train_normal_curvature.py scaling/experiments/train_normal_curvature.py
--- 15648/experiments/train_normal_curvature.py	2018-11-02 01:46:24.000000001 -0700
+++ scaling/experiments/train_normal_curvature.py	2018-10-30 00:37:39.000000001 -0700
@@ -14,7 +14,7 @@
 from datasets import ImageTaskDataset
 from torch.optim.lr_scheduler import MultiStepLR
 
-from modules.percep_nets import DenseNet, DeepNet, BaseNet, ResidualsNet, WideNet, PyramidNet
+from modules.percep_nets import DenseNet, DeepNet, BaseNet, ResidualsNet, WideNet, PyramidNet, Dense1by1Net, DenseKernelsNet
 
 import IPython
 
@@ -22,13 +22,13 @@
 if __name__ == "__main__":
 
     # MODEL
-    print ("Using PyramidNet")
-    model = DataParallelModel(PyramidNet())
+    print ("Using Dense1by1Net")
+    model = DataParallelModel(Dense1by1Net())
     model.compile(torch.optim.Adam, lr=2e-4, weight_decay=2e-6, amsgrad=True)
-    print (model.forward(torch.randn(1, 3, 512, 512)).shape)
+    print (model.forward(torch.randn(1, 3, 256, 256)).shape)
 
     def loss(pred, target):
-        mask = build_mask(target, val=0.0, tol=1e-2)
+        mask = build_mask(target, val=0.0, tol=1e-3)
         mse = F.mse_loss(pred[mask], target[mask])
         unmask_mse = F.mse_loss(pred, target)
         return mse, (mse.detach(), unmask_mse.detach())
@@ -50,12 +50,12 @@
     logger.add_hook(lambda x: model.save(f"{RESULTS_DIR}/model.pth"), feature='loss', freq=400)
 
     train_loader, val_loader, test_set, test_images, ood_images, train_step, val_step = \
-        load_data("normal", "principal_curvature", batch_size=64)
+        load_data("normal", "principal_curvature", mask_val=0.0, batch_size=64, dilate=9)
     logger.images(test_images, "images", resize=128)
     plot_images(model, logger, test_set, mask_val=0.0)
 
     # TRAINING
-    for epochs in range(0, 200):
+    for epochs in range(0, 800):
         
         logger.update('epoch', epochs)
         
diff -bur 15648/experiments/train_normal_zdepth.py scaling/experiments/train_normal_zdepth.py
--- 15648/experiments/train_normal_zdepth.py	2018-11-02 01:46:23.000000001 -0700
+++ scaling/experiments/train_normal_zdepth.py	2018-10-30 19:41:45.000000001 -0700
@@ -27,10 +27,10 @@
     model = DataParallelModel(UNetDepth())
     print ("Loader model")
     model.compile(torch.optim.Adam, lr=3e-4, weight_decay=2e-6, amsgrad=True)
-    print (model.forward(torch.randn(1, 3, 512, 512)).shape)
+    print (model.forward(torch.randn(1, 3, 256, 256)).shape)
 
     def loss(pred, target):
-        mask = build_mask(target, val=1.0, tol=1e-2)
+        mask = build_mask(target, val=1.0, tol=1e-3)
         mse = F.mse_loss(pred*mask.float(), target*mask.float())
         return mse, (mse.detach(),)
 
@@ -47,14 +47,10 @@
 
     # DATA LOADING
     def dest_transforms(x):
-        x = x.unsqueeze(0)
-        mask = build_mask(x, 65535.0, tol=1000)
-        x[~mask] = 8000.0
-        x = x/8000.0
-        return x[0]
+        return (x.float()/10000.0).clamp(min=0.0, max=1.0)
 
     train_loader, val_loader, test_set, test_images, ood_images, train_step, val_step = \
-        load_data("normal", "depth_zbuffer", batch_size=48, dest_transforms=dest_transforms)
+        load_data("normal", "depth_zbuffer", batch_size=64, dilate=5, dest_transforms=dest_transforms)
     logger.images(test_images, "images", resize=128)    
     plot_images(model, logger, test_set, mask_val=1.0)
 
diff -bur 15648/experiments/train_perceptuals.py scaling/experiments/train_perceptuals.py
--- 15648/experiments/train_perceptuals.py	2018-11-02 01:46:24.000000001 -0700
+++ scaling/experiments/train_perceptuals.py	2018-11-01 16:57:42.000000001 -0700
@@ -1,102 +1,81 @@
-
-import os, sys, math, random, itertools
-import numpy as np
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-
-from torchvision import datasets, transforms, models
+from fire import Fire
+from logger import VisdomLogger
+from models import DataParallelModel
+from modules.depth_nets import UNetDepth
+from modules.percep_nets import Dense1by1Net
+from modules.resnet import ResNet
 from torch.optim.lr_scheduler import MultiStepLR
 from torch.utils.checkpoint import checkpoint
-
 from utils import *
+
 from models import TrainableModel, DataParallelModel
 from logger import Logger, VisdomLogger
 from datasets import ImageTaskDataset
 
 from modules.resnet import ResNet
-from modules.percep_nets import DenseNet, DeepNet, BaseNet, WideNet, PyramidNet, Dense1by1Net, DenseKernelsNet
+from modules.percep_nets import DenseNet, Dense1by1Net, DenseKernelsNet, DeepNet, BaseNet, WideNet, PyramidNet
 from modules.depth_nets import UNetDepth
 from modules.unet import UNet
 from sklearn.model_selection import train_test_split
 from fire import Fire
 
-import IPython
-
 
 def main(curvature_step=0, depth_step=0):
-
     curvature_weight = 0.0
     depth_weight = 0.0
 
+    # LOGGING
+    logger = VisdomLogger("train", env=JOB)
+    logger.add_hook(lambda x: logger.step(), feature="loss", freq=25)
+
     # MODEL
     model = DataParallelModel(UNet())
+    # model = DataParallelModel.load(UNet().cuda(), f"{MODELS_DIR}/rgb2normal_unet.pth")
     model.compile(torch.optim.Adam, lr=3e-4, weight_decay=2e-6, amsgrad=True)
 
     print (model.forward(torch.randn(8, 3, 256, 256)).shape)
     
-    # for i in range(20):
-    #     print (model.forward(torch.randn(160 + (8*i), 3, 256, 256)).shape)
-
-    scheduler = MultiStepLR(model.optimizer, milestones=[5*i + 1 for i in range(0, 80)], gamma=0.95)
-
+    scheduler = MultiStepLR(model.optimizer, milestones=[5 * i + 1 for i in range(0, 80)], gamma=0.95)
     curvature_model_base = DataParallelModel.load(Dense1by1Net().cuda(), f"{MODELS_DIR}/normal2curvature_dense_1x1.pth")
-    def curvature_model(pred):
-        return checkpoint(curvature_model_base, pred)
+    depth_model_base = DataParallelModel.load(UNetDepth().cuda(), f"{MODELS_DIR}//normal2zdepth_unet.pth")
 
-    depth_model_base = None#DataParallelModel.load(UNetDepth().cuda(), f"{MODELS_DIR}/normal2zdepth_unet.pth")
     def depth_model(pred):
         return checkpoint(depth_model_base, pred)
 
+    def curvature_model(pred):
+        return checkpoint(curvature_model_base, pred)
+
     def mixed_loss(pred, target):
         mask = build_mask(target.detach(), val=0.502)
-        mse = F.mse_loss(pred*mask.float(), target*mask.float())
-        curvature = torch.tensor(0.0, device=mse.device) if curvature_weight == 0.0 else \
-            F.mse_loss(curvature_model(pred)*mask.float(), curvature_model(target)*mask.float())
-        depth = torch.tensor(0.0, device=mse.device) if depth_weight == 0.0 else \
-            F.mse_loss(depth_model(pred)*mask.float(), depth_model(target)*mask.float())
-
-        return mse + curvature_weight*curvature  + depth_weight*depth, (mse.detach(), curvature.detach(), depth.detach())
-
-    # LOGGING
-    logger = VisdomLogger("train", env=JOB)
-    logger.add_hook(lambda x: logger.step(), feature="loss", freq=25)
-
-    def get_running_means_w_std_bounds_and_legend(list_of_values):
-        running_mean_and_std_bounds = []
-        legend = ["Mean-STD", "Mean", "Mean+STD"]
-        for ii in range(len(list_of_values)):
-            mean = np.mean(list_of_values[:ii])
-            std = np.std(list_of_values[:ii])
-
-            running_mean_and_std_bounds.append([mean-std, mean, mean+std])
-
-        return running_mean_and_std_bounds, legend
+        mse = F.mse_loss(pred * mask.float(), target * mask.float())
+        curvature = F.mse_loss(curvature_model(pred) * mask.float(), curvature_model(target) * mask.float())
+        depth = F.mse_loss(depth_model(pred) * mask.float(), depth_model(target) * mask.float())
+
+        def standardize_gradients(curvature, depth):
+            def forward(curvature_depth):
+                return curvature, depth
+
+            def backward(curvature_grad, depth_grad):
+                # return complex formula
+
+        curvature, depth = standardize_gradients(curvature, depth)
+
+        final_loss = mse + curvature + depth
+        metrics_to_return = (mse.detach(), curvature.detach(), depth.detach())
+        return final_loss, metrics_to_return
 
     def jointplot1(data):
-        # compute running mean for every
         data = np.stack((logger.data["train_mse_loss"], logger.data["val_mse_loss"]), axis=1)
         logger.plot(data, "mse_loss", opts={"legend": ["train_mse", "val_mse"]})
 
-        # running_mean_and_std_bounds, legend = get_running_means_w_std_bounds_and_legend(logger.data["train_mse_loss"])
-        # logger.plot(running_mean_and_std_bounds, "mse_loss_running_mean", opts={"legend": legend})
-
     def jointplot2(data):
         data = np.stack((logger.data["train_curvature_loss"], logger.data["val_curvature_loss"]), axis=1)
         logger.plot(data, "curvature_loss", opts={"legend": ["train_curvature", "val_curvature"]})
 
-        # running_mean_and_std_bounds, legend = get_running_means_w_std_bounds_and_legend(logger.data["train_curvature_loss"])
-        # logger.plot(running_mean_and_std_bounds, "curvature_loss_running_mean", opts={"legend": legend})
-
-
     def jointplot3(data):
         data = np.stack((logger.data["train_depth_loss"], logger.data["val_depth_loss"]), axis=1)
         logger.plot(data, "depth_loss", opts={"legend": ["train_depth", "val_depth"]})
 
-        # running_mean_and_std_bounds, legend = get_running_means_w_std_bounds_and_legend(logger.data["train_depth_loss"])
-        # logger.plot(running_mean_and_std_bounds, "depth_loss_running_mean", opts={"legend": legend})
-
     logger.add_hook(jointplot1, feature="val_mse_loss", freq=1)
     logger.add_hook(jointplot2, feature="val_curvature_loss", freq=1)
     logger.add_hook(jointplot3, feature="val_depth_loss", freq=1)
@@ -108,7 +87,7 @@
     logger.images(test_images, "images", resize=128)
     logger.images(torch.cat(ood_images, dim=0), "ood_images", resize=128)
     plot_images(model, logger, test_set, ood_images, mask_val=0.502, 
-        loss_models={"curvature": curvature_model})#, "depth": depth_model})
+                loss_models={"curvature": curvature_model, "depth": depth_model})
 
     # TRAINING
     for epochs in range(0, 800):
@@ -122,21 +101,6 @@
         logger.update("train_curvature_loss", np.mean(curvature_data))
         logger.update("train_depth_loss", np.mean(depth_data))
 
-        # TODO clear out logs first, before appending to this
-        # Used to log losses in case we want to analyze them afterwards for whitening
-        # temp_logs_location = f"{BASE_DIR}/temp_logs"
-        # with open(f"{temp_logs_location}/log_train_mse_losses.txt", "a") as log_file:
-        #     log_file.write(', '.join([str(dd.cpu().tolist()) for dd in mse_data]))
-        #     log_file.write("\n")
-
-        # with open(f"{temp_logs_location}/log_train_curvature_loss.txt", "a") as log_file:
-        #     log_file.write(', '.join([str(dd.cpu().tolist()) for dd in curvature_data]))
-        #     log_file.write("\n")
-
-        # with open(f"{temp_logs_location}/log_train_depth_loss.txt", "a") as log_file:
-        #     log_file.write(', '.join([str(dd.cpu().tolist()) for dd in depth_data]))
-        #     log_file.write("\n")
-
         val_set = itertools.islice(val_loader, val_step)
         (mse_data, curvature_data, depth_data) = model.predict_with_metrics(
             val_set, loss_fn=mixed_loss, logger=logger
@@ -145,26 +109,16 @@
         logger.update("val_curvature_loss", np.mean(curvature_data))
         logger.update("val_depth_loss", np.mean(depth_data))
 
-        # if epochs > 250:
-        #     curvature_weight = curvature_step
-
         curvature_weight += curvature_step
         depth_weight += depth_step
-        logger.text (f"Increasing curvature weight: {curvature_weight}")
-        logger.text (f"Increasing depth weight: {depth_weight}")
-        
-        def mixed_loss(pred, target):
-            mask = build_mask(target.detach(), val=0.502)
-            mse = F.mse_loss(pred*mask.float(), target*mask.float())
-            curvature = torch.tensor(0.0, device=mse.device) if curvature_weight == 0.0 else \
-                F.mse_loss(curvature_model(pred)*mask.float(), curvature_model(target)*mask.float())
-            depth = torch.tensor(0.0, device=mse.device) if depth_weight == 0.0 else \
-                F.mse_loss(depth_model(pred)*mask.float(), depth_model(target)*mask.float())
+        logger.text(f"Increasing curvature weight: {curvature_weight}")
+        logger.text(f"Increasing depth weight: {depth_weight}")
 
-            return mse + curvature_weight*curvature  + depth_weight*depth, (mse.detach(), curvature.detach(), depth.detach())
+        if epochs == 75:
+            depth_weight = 10.0
 
         plot_images(model, logger, test_set, ood_images, mask_val=0.502, 
-                        loss_models={"curvature": curvature_model})#, "depth": depth_model})
+                    loss_models={"curvature": curvature_model, "depth": depth_model})
 
         scheduler.step()
 
Only in scaling/experiments: train_perceptuals_resize.py
diff -bur 15648/experiments/train_rgb_normal.py scaling/experiments/train_rgb_normal.py
--- 15648/experiments/train_rgb_normal.py	2018-11-02 01:46:25.000000001 -0700
+++ scaling/experiments/train_rgb_normal.py	2018-10-29 22:08:00.000000001 -0700
@@ -17,6 +17,7 @@
 from modules.resnet import ResNet
 from modules.percep_nets import DenseNet, DeepNet, BaseNet
 from modules.depth_nets import UNetDepth
+from modules.drn import DRN
 from modules.unet import UNet
 from sklearn.model_selection import train_test_split
 from fire import Fire
@@ -30,7 +31,7 @@
     depth_weight = 0.0
 
     # MODEL
-    model = DataParallelModel(ResNet())
+    model = DataParallelModel(DRN())
     # model = DataParallelModel.load(ResNet().cuda(), f"{RESULTS_DIR}/model.pth")
     model.compile(torch.optim.Adam, lr=5e-4, weight_decay=2e-6, amsgrad=True)
 
Only in scaling/experiments: train_standardization.py
Only in scaling/experiments: train_task.py
Only in scaling: .git
Only in scaling: jobinfo.txt
Only in scaling/jobs: augmented.sh
diff -bur 15648/jobs/curvenets.sh scaling/jobs/curvenets.sh
--- 15648/jobs/curvenets.sh	2018-11-02 01:46:24.000000001 -0700
+++ scaling/jobs/curvenets.sh	2018-10-30 21:20:46.000000001 -0700
@@ -1,3 +1,3 @@
 
-job run --config "curvenet_dense_baseline" "python -m experiments.train_perceptual_curvature";
-job run --config "curvenet_dense_step0.05" "python -m experiments.train_perceptual_curvature --weight-step 0.05";
+job run --config "cycleconsistency_curvature_mse_cycle" "python -m experiments.train_perceptual_curvature --mse-weight 1.0 --cycle-weight 1.0";
+job run --config "cycleconsistency_curvature_only_cycle" "python -m experiments.train_perceptual_curvature --mse-weight 0.0 --cycle-weight 1.0";
Only in scaling/jobs: cycleconsistency.sh
Only in scaling/jobs: diff.txt
diff -bur 15648/jobs/mixedperceptuals.sh scaling/jobs/mixedperceptuals.sh
--- 15648/jobs/mixedperceptuals.sh	2018-11-02 01:46:30.000000001 -0700
+++ scaling/jobs/mixedperceptuals.sh	2018-11-01 17:26:30.000000001 -0700
@@ -1,4 +1,6 @@
 
-# job run --config "group_baseline" "python -m experiments.train_perceptuals"
-job run --config "nvidia_percep_curvature" "python -m experiments.train_perceptuals --curvature-step 0.01"
-job run --config "nvidia_percep_curvedepth" "python -m experiments.train_perceptuals --curvature-step 0.01 --depth-step 0.005"
\ No newline at end of file
+# job run --config "percep_depth0.01" "python -m experiments.train_perceptuals --depth-step 0.01"
+job run --config "oldpercep_depth0.05" "python -m experiments.train_perceptuals --depth-step 0.05"
+# job run --config "percep_depth0.1" "python -m experiments.train_perceptuals --depth-step 0.1"
+#job run --config "percep_depth0.2" "python -m experiments.train_perceptuals --depth-step 0.2"
+#job run --config "percep_depth0.5" "python -m experiments.train_perceptuals --depth-step 0.5"
\ No newline at end of file
Only in scaling/jobs: standardization.sh
diff -bur 15648/modules/depth_nets.py scaling/modules/depth_nets.py
--- 15648/modules/depth_nets.py	2018-11-02 01:46:24.000000001 -0700
+++ scaling/modules/depth_nets.py	2018-10-31 00:37:47.000000001 -0700
@@ -101,9 +101,9 @@
         self.down_block2 = UNet_down_block(16, 32, True)
         self.down_block3 = UNet_down_block(32, 64, True)
         self.down_block4 = UNet_down_block(64, 128, True)
-        self.down_block5 = UNet_down_block(128, 256, False)
-        self.down_block6 = UNet_down_block(256, 512, False)
-        self.down_block7 = UNet_down_block(512, 1024, True)
+        self.down_block5 = UNet_down_block(128, 256, True)
+        self.down_block6 = UNet_down_block(256, 512, True)
+        self.down_block7 = UNet_down_block(512, 1024, False)
 
         self.mid_conv1 = nn.Conv2d(1024, 1024, 3, padding=1)
         self.bn1 = nn.GroupNorm(8, 1024)
@@ -112,9 +112,9 @@
         self.mid_conv3 = torch.nn.Conv2d(1024, 1024, 3, padding=1)
         self.bn3 = torch.nn.GroupNorm(8, 1024)
 
-        self.up_block1 = UNet_up_block(512, 1024, 512)
-        self.up_block2 = UNet_up_block(256, 512, 256, False)
-        self.up_block3 = UNet_up_block(128, 256, 128, False)
+        self.up_block1 = UNet_up_block(512, 1024, 512, False)
+        self.up_block2 = UNet_up_block(256, 512, 256, True)
+        self.up_block3 = UNet_up_block(128, 256, 128, True)
         self.up_block4 = UNet_up_block(64, 128, 64, True)
         self.up_block5 = UNet_up_block(32, 64, 32, True)
         self.up_block6 = UNet_up_block(16, 32, 16, True)
Only in scaling/modules: drn.py
Only in 15648/modules/__pycache__: depth_nets.cpython-36.pyc
Only in scaling/modules/__pycache__: depth_nets.cpython-37.pyc
Only in 15648/modules/__pycache__: __init__.cpython-36.pyc
Only in scaling/modules/__pycache__: __init__.cpython-37.pyc
Only in 15648/modules/__pycache__: percep_nets.cpython-36.pyc
Only in scaling/modules/__pycache__: percep_nets.cpython-37.pyc
Only in 15648/modules/__pycache__: resnet.cpython-36.pyc
Only in scaling/modules/__pycache__: resnet.cpython-37.pyc
Only in 15648/modules/__pycache__: unet.cpython-36.pyc
Only in scaling/modules/__pycache__: unet.cpython-37.pyc
diff -bur 15648/modules/resnet.py scaling/modules/resnet.py
--- 15648/modules/resnet.py	2018-11-02 01:46:23.000000001 -0700
+++ scaling/modules/resnet.py	2018-10-27 12:54:57.000000001 -0700
@@ -12,11 +12,12 @@
 from models import TrainableModel
 from utils import *
 
+
 class ConvBlock(nn.Module):
-    def __init__(self, f1, f2, use_groupnorm=True, groups=8, dilation=1, transpose=False):
+    def __init__(self, f1, f2, kernel_size=3, padding=1, use_groupnorm=True, groups=8, dilation=1, transpose=False):
         super().__init__()
         self.transpose = transpose
-        self.conv = nn.Conv2d(f1, f2, (3, 3), dilation=dilation, padding=dilation)
+        self.conv = nn.Conv2d(f1, f2, (kernel_size, kernel_size), dilation=dilation, padding=padding*dilation)
         if self.transpose:
             self.convt = nn.ConvTranspose2d(
                 f1, f1, (3, 3), dilation=dilation, stride=2, padding=dilation, output_padding=1
@@ -24,7 +25,7 @@
         if use_groupnorm:
             self.bn = nn.GroupNorm(groups, f1)
         else:
-            self.bn = nn.GroupNorm(8, f1)
+            self.bn = nn.BatchNorm2d(f1)
 
     def forward(self, x):
         # x = F.dropout(x, 0.04, self.training)
@@ -79,7 +80,12 @@
     def __init__(self, block, layers, num_classes=1000):
         self.inplanes = 64
         super(ResNetOriginal, self).__init__()
-        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
+        self.initial = nn.Sequential(
+            ConvBlock(3, 16, groups=3, kernel_size=1, padding=0),
+            ConvBlock(16, 16, groups=4, kernel_size=1, padding=0)
+        )
+
+        self.conv1 = nn.Conv2d(16, 64, kernel_size=7, stride=2, padding=3,
                                bias=False)
         self.bn1 = nn.GroupNorm(8, 64)
         self.relu = nn.ReLU(inplace=True)
@@ -116,6 +122,7 @@
         return nn.Sequential(*layers)
 
     def forward(self, x):
+        x = self.initial(x)
         x = self.conv1(x)
         x = self.bn1(x)
         x = self.relu(x)
diff -bur 15648/modules/unet.py scaling/modules/unet.py
--- 15648/modules/unet.py	2018-11-02 01:46:25.000000001 -0700
+++ scaling/modules/unet.py	2018-10-31 03:50:48.000000001 -0700
@@ -13,6 +13,32 @@
 from utils import *
 
 
+
+class ConvBlock(nn.Module):
+    def __init__(self, f1, f2, kernel_size=3, padding=1, use_groupnorm=True, groups=8, dilation=1, transpose=False):
+        super().__init__()
+        self.transpose = transpose
+        self.conv = nn.Conv2d(f1, f2, (kernel_size, kernel_size), dilation=dilation, padding=padding*dilation)
+        if self.transpose:
+            self.convt = nn.ConvTranspose2d(
+                f1, f1, (3, 3), dilation=dilation, stride=2, padding=dilation, output_padding=1
+            )
+        if use_groupnorm:
+            self.bn = nn.GroupNorm(groups, f1)
+        else:
+            self.bn = nn.BatchNorm2d(f1)
+
+    def forward(self, x):
+        # x = F.dropout(x, 0.04, self.training)
+        x = self.bn(x)
+        if self.transpose:
+            # x = F.upsample(x, scale_factor=2, mode='bilinear')
+            x = F.relu(self.convt(x))
+            # x = x[:, :, :-1, :-1]
+        x = F.relu(self.conv(x))
+        return x
+
+
 class UNet_up_block(nn.Module):
     def __init__(self, prev_channel, input_channel, output_channel, up_sample=True):
         super().__init__()
@@ -91,6 +117,7 @@
         self.relu = nn.ReLU()
 
     def forward(self, x):
+
         self.x1 = self.down_block1(x)
         self.x2 = self.down_block2(self.x1)
         self.x3 = self.down_block3(self.x2)
Binary files 15648/__pycache__/datasets.cpython-36.pyc and scaling/__pycache__/datasets.cpython-36.pyc differ
Only in scaling/__pycache__: datasets.cpython-37.pyc
Binary files 15648/__pycache__/logger.cpython-36.pyc and scaling/__pycache__/logger.cpython-36.pyc differ
Only in scaling/__pycache__: logger.cpython-37.pyc
Binary files 15648/__pycache__/models.cpython-36.pyc and scaling/__pycache__/models.cpython-36.pyc differ
Only in scaling/__pycache__: models.cpython-37.pyc
Only in 15648/__pycache__: modules.cpython-36.pyc
Binary files 15648/__pycache__/utils.cpython-36.pyc and scaling/__pycache__/utils.cpython-36.pyc differ
Only in scaling/__pycache__: utils.cpython-37.pyc
Only in scaling/scripts: files.txt
diff -bur 15648/scripts/jobinfo.txt scaling/scripts/jobinfo.txt
--- 15648/scripts/jobinfo.txt	2018-11-02 01:46:24.000000001 -0700
+++ scaling/scripts/jobinfo.txt	2018-11-01 17:26:40.000000001 -0700
@@ -1 +1 @@
-unet_percepstep_0.1_1, 0, /
+oldpercep_depth0.05_1, 0, /
Only in scaling/scripts: jobinfo.yml
Binary files 15648/scripts/__pycache__/__init__.cpython-35.pyc and scaling/scripts/__pycache__/__init__.cpython-35.pyc differ
Binary files 15648/scripts/__pycache__/__init__.cpython-36.pyc and scaling/scripts/__pycache__/__init__.cpython-36.pyc differ
Only in scaling/scripts/__pycache__: __init__.cpython-37.pyc
Only in 15648/scripts/__pycache__: run3.cpython-36.pyc
Binary files 15648/scripts/__pycache__/run.cpython-35.pyc and scaling/scripts/__pycache__/run.cpython-35.pyc differ
Only in scaling/scripts/__pycache__: untar_data.cpython-36.pyc
Only in scaling/scripts/__pycache__: untar_data.cpython-37.pyc
diff -bur 15648/scripts/run2.py scaling/scripts/run2.py
--- 15648/scripts/run2.py	2018-11-02 01:46:24.000000001 -0700
+++ scaling/scripts/run2.py	2018-10-26 19:34:21.000000001 -0700
@@ -43,7 +43,7 @@
     process = subprocess.Popen(cmd, shell=False, stdout=subprocess.PIPE, universal_newlines=True)
 
     try:
-        with open(f"checkpoints/{run_name}/stdout.txt", "w") as outfile:
+        with open(f"mount/shared/results_{run_name}/stdout.txt", "w") as outfile:
             for stdout_line in iter(process.stdout.readline, ""):
                 print(stdout_line, end="")
                 outfile.write(stdout_line)
@@ -79,7 +79,7 @@
         subprocess.call("sudo shutdown -h now", shell=True)
 
 def run(cmd, config="default", experiment_id=None, shutdown=False, debug=False):
-    cmd = f""" screen -S {config} bash -c "sudo /home/shared/anaconda3/bin/python -m scripts.run2 execute \\"{cmd}\\" --config {config} --experiment-id {experiment_id} --shutdown {shutdown} --debug {debug}; bash" """
+    cmd = f""" screen -S {config} bash -c "sudo /home/shared/anaconda3/bin/python -m scripts.run2 execute \\"{cmd}\\" --config {config} --experiment-id {experiment_id} --shutdown {shutdown} --debug {debug} && bash" """
     subprocess.call(shlex.split(cmd))
 
 
diff -bur 15648/scripts/run3.py scaling/scripts/run3.py
--- 15648/scripts/run3.py	2018-11-02 01:46:24.000000001 -0700
+++ scaling/scripts/run3.py	2018-10-30 00:24:21.000000001 -0700
@@ -15,8 +15,9 @@
     os.system(f"echo {exp_id}, 0, mount > scripts/jobinfo.txt")
     subprocess.run(["rsync", "-av", "--progress", ".", "checkpoints/" + exp_id, "--exclude",
         "checkpoints", "--exclude", ".git", "--exclude", "data/snapshots", "--exclude", "data/results"],
-        stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
-    subprocess.run(f"gsutil -m cp -r checkpoints/{exp_id} gs://taskonomy-code".split(), stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
+        stdout=subprocess.DEVNULL)
+    subprocess.run(f"gsutil -m cp -r checkpoints/{exp_id} gs://taskonomy-code".split(),
+        stdout=subprocess.DEVNULL)
 
 def delete(env):
     import visdom
@@ -33,10 +34,11 @@
     cmd = shlex.split(cmd)
     if cmd[0] == "python":
         cmd[0] = "/home/shared/anaconda3/bin/python"
+        cmd.insert(1, "-u")
         cmd.insert(0, "sudo")
     cmd = " ".join(cmd)
 
-    with open('/Users/rohan/.sshrc', 'w') as outfile:
+    with open('/Users/nikcheerla/.sshrc', 'w') as outfile:
         print (f"gsutil -m cp -r gs://taskonomy-code/{exp_id}/* .", file=outfile)
         print (f"""sudo /home/shared/anaconda3/bin/python -m scripts.run2 run --config "{config}" --experiment-id "{exp_id}" --shutdown {shutdown} "{cmd}" """, file=outfile)
     
diff -bur 15648/scripts/untar_data.py scaling/scripts/untar_data.py
--- 15648/scripts/untar_data.py	2018-11-02 01:46:30.000000001 -0700
+++ scaling/scripts/untar_data.py	2018-11-01 12:14:59.000000001 -0700
@@ -3,7 +3,7 @@
 from multiprocessing import Pool
 from fire import Fire
 
-def process_file(file, result_loc="staging"):
+def process_file(file, result_loc="/result"):
 	try:
 		*rest, task, archive = file.split('/')
 		result_dir = f"{result_loc}/{archive[:-4]}"
@@ -11,15 +11,13 @@
 		curl = subprocess.Popen(["curl", "-s", file], stdout=subprocess.PIPE)
 		tar = subprocess.Popen(["tar", "xf", "-", "-C", result_dir, "--no-same-owner"], stdin=curl.stdout, stdout=subprocess.PIPE)
 		tar.wait()
-		subprocess.run(f"gsutil -m cp -r {result_dir} gs://taskonomy-data".split(), stdout=devnull, stderr=devnull)
-		subprocess.run(f"rm -rf {result_dir}".split(), stdout=devnull, stderr=devnull)
 		return result_dir
 	except Exception as e:
 		print (e)
 		return "error"
 
 def main(filename="data/alllinks.txt", 
-		tasks=['rgb', 'normal','principal_curvature', 'depth_zbuffer']):
+		tasks=['normal', 'reshading']):
 	
 	links = [link.strip() for link in open(filename, 'r')]
 	links = [(link, link.split('/')) for link in links]
@@ -28,7 +26,6 @@
 	with Pool() as pool:
 		for i, result_dir in enumerate(pool.imap_unordered(process_file, links)):
 			print (f"Downloaded {result_dir}: {i}/{len(links)} files")
-			break
 
 if __name__ == "__main__":
 	Fire(main)
diff -bur 15648/utils.py scaling/utils.py
--- 15648/utils.py	2018-11-02 01:46:25.000000001 -0700
+++ scaling/utils.py	2018-10-31 03:53:41.000000001 -0700
@@ -5,20 +5,21 @@
 
 from sklearn.model_selection import train_test_split
 
+import IPython
+import PIL
+
 EXPERIMENT, RESUME_JOB, BASE_DIR = open("scripts/jobinfo.txt").read().strip().split(', ')
 JOB = "_".join(EXPERIMENT.split("_")[0:-1])
 
 MODELS_DIR = f"{BASE_DIR}/shared/models"
 DATA_DIR = f"{BASE_DIR}/data/taskonomy3"
 RESULTS_DIR = f"{BASE_DIR}/shared/results_{EXPERIMENT}"
+os.system(f"sudo mkdir {RESULTS_DIR}")
 
 if BASE_DIR == "/":
+    MODELS_DIR = "/models"
     DATA_DIR = "/data"
     RESULTS_DIR = "/result"
-    MODELS_DIR = "/models"
-else:
-    os.system(f"sudo mkdir -p {RESULTS_DIR}")
-
 
 print("Models dir: ", MODELS_DIR)
 print("Results dir: ", RESULTS_DIR)
@@ -32,6 +33,7 @@
     from torch.autograd import Variable
 
     DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+    dtype = torch.cuda.FloatTensor
 except:
     pass
 
@@ -69,21 +71,38 @@
         for i in iterable:
             yield i
 
+# Cycles through iterable without making extra copies
+def random_resize(iterable, vals=[128, 192, 256, 320]):
+    from transforms import resize
+    while True:
+        for X, Y in iterable:
+            val = random.choice(vals)
+            yield resize(X.to(DEVICE), val=val).detach(), resize(Y.to(DEVICE), val=val).detach()
 
-def build_mask(target, val=0.0, tol=1e-3):
+def build_mask(target, val=0.0, tol=1e-3, dilate=None):
     if target.shape[1] == 1:
-        return ~((target >= val - tol) & (target <= val + tol))
+        mask = (target[:, 0, :, :] >= val - tol) & (target[:, 0, :, :] <= val + tol)
+        mask = mask.unsqueeze(1)
+        mean = mask.data.float().mean()
+        if dilate is not None:
+            mask = F.conv2d(mask.float(), torch.ones(1, 1, dilate, dilate, device=mask.device), padding=dilate//2) != 0
+        mask = (~mask).expand_as(target)
+        return mask
 
     mask1 = (target[:, 0, :, :] >= val - tol) & (target[:, 0, :, :] <= val + tol)
     mask2 = (target[:, 1, :, :] >= val - tol) & (target[:, 1, :, :] <= val + tol)
     mask3 = (target[:, 2, :, :] >= val - tol) & (target[:, 2, :, :] <= val + tol)
     mask = (mask1 & mask2 & mask3).unsqueeze(1)
-    mask = F.conv2d(mask.float(), torch.ones(1, 1, 7, 7, device=mask.device), padding=3) != 0
+    if dilate is not None :
+        mask = F.conv2d(mask.float(), torch.ones(1, 1, dilate, dilate, device=mask.device), padding=dilate//2) != 0
+
     mask = (~mask).expand_as(target)
     return mask
 
 
-def load_data(source_task, dest_task, source_transforms=None, dest_transforms=None, batch_size=32, resize=256):
+def load_data(source_task, dest_task, source_transforms=None, dest_transforms=None, batch_size=32, 
+                resize=256, mask_val=0.502, dilate=5, batch_transforms=cycle):
+    
     from datasets import ImageTaskDataset, ImageDataset
     from torchvision import transforms
 
@@ -98,16 +117,29 @@
     #                         if train == "1" and building not in test_buildings]
     # val_buildings = [building for building, train, test, val in building_tags if val == "1"]
 
-    source_transforms = source_transforms or (lambda x: x)
-    dest_transforms = dest_transforms or (lambda x: x)
-    source_transforms = transforms.Compose([transforms.Resize(resize), transforms.ToTensor(), source_transforms])
-    dest_transforms = transforms.Compose([transforms.Resize(resize), transforms.ToTensor(), dest_transforms])
+    t_resize = transforms.Compose([transforms.ToPILImage(), transforms.Resize(resize, interpolation=PIL.Image.NEAREST), 
+                                    transforms.ToTensor()])
+
+    def dilated_kernel(x):
+        mask = build_mask(x.unsqueeze(0), mask_val, dilate=dilate)
+        mask = t_resize(~mask[0])
+        mask = (mask == 0).float()
+        x = t_resize(x)
+        x = x*mask.float() + mask_val*(1-mask.float())
+        return x
+
+    if source_transforms != None:
+        source_transforms = transforms.Compose([transforms.Resize(resize), transforms.ToTensor()])
+    else:
+        source_transforms = transforms.Compose([transforms.ToTensor(), source_transforms or (lambda x: x), dilated_kernel])
+
+    dest_transforms = transforms.Compose([transforms.ToTensor(), dest_transforms or (lambda x: x), dilated_kernel])
 
     train_loader = torch.utils.data.DataLoader(
         ImageTaskDataset(buildings=train_buildings, source_transforms=source_transforms, dest_transforms=dest_transforms,
                          source_task=source_task, dest_task=dest_task),
         batch_size=batch_size,
-        num_workers=32,
+        num_workers=64,
         shuffle=True,
         pin_memory=True
     )
@@ -115,30 +147,27 @@
         ImageTaskDataset(buildings=val_buildings, source_transforms=source_transforms, dest_transforms=dest_transforms,
                          source_task=source_task, dest_task=dest_task),
         batch_size=batch_size,
-        num_workers=32,
+        num_workers=64,
         shuffle=True,
         pin_memory=True
     )
     test_loader1 = torch.utils.data.DataLoader(
         ImageTaskDataset(buildings=["almena"], source_transforms=source_transforms, dest_transforms=dest_transforms,
-                         source_task=source_task, dest_task=dest_task),
+                         source_task=source_task, dest_task=dest_task, debug=True),
         batch_size=6,
-        num_workers=12,
         shuffle=False,
-        pin_memory=True
+        pin_memory=True,
     )
     test_loader2 = torch.utils.data.DataLoader(
         ImageTaskDataset(buildings=["albertville"], source_transforms=source_transforms, dest_transforms=dest_transforms,
-                         source_task=source_task, dest_task=dest_task),
+                         source_task=source_task, dest_task=dest_task, debug=True),
         batch_size=6,
-        num_workers=6,
         shuffle=False,
-        pin_memory=True
+        pin_memory=True,
     )
     ood_loader = torch.utils.data.DataLoader(
-        ImageDataset(data_dir="data/ood_images"),
+        ImageDataset(data_dir="data/ood_images", resize=(resize, resize)),
         batch_size=10,
-        num_workers=10,
         shuffle=False,
         pin_memory=True
     )
@@ -147,7 +176,7 @@
     print("Train step: ", train_step)
     print("Val step: ", val_step)
 
-    train_loader, val_loader = cycle(train_loader), cycle(val_loader)
+    train_loader, val_loader = batch_transforms(train_loader), batch_transforms(val_loader)
     test_set = list(itertools.islice(test_loader1, 1)) + list(itertools.islice(test_loader2, 1))
     test_images = torch.cat([x for x, y in test_set], dim=0)
     ood_images = list(itertools.islice(ood_loader, 1))
@@ -161,6 +190,7 @@
     logger.images(test_masks.float(), "masks", resize=256)
     logger.images(preds.clamp(min=0, max=1), "predictions", nrow=2, resize=256)
     logger.images(targets.clamp(min=0, max=1), "targets", nrow=2, resize=256)
+    logger.images(targets.clamp(min=0, max=1)*test_masks.float() + (1-mask_val)*(1 - test_masks.float()), "targets_masked", nrow=2, resize=256)
 
     if ood_images is not None:
         ood_preds = model.predict(ood_images)
